# 1. 입력 이미지 전처리에서 왜 HSV 색공간으로 변환하고, 노이즈를 제거하는가?
영상 처리에서 가장 중요한 첫걸음은 **입력된 이미지로부터 우리가 필요한 정보만 뽑아내기 위한 준비 작업**, 즉 '전처리'이다. 당구 테이블에서 공의 위치를 정확하게 검출하고자 할 때, 우리는 우선 **색상 정보를 기준으로 테이블과 공을 구분**하려고 한다. 그런데 여기서 문제가 발생한다. 일반적으로 우리가 접하는 이미지 색상은 RGB 형식인데, 이 방식은 공이나 테이블의 **조명에 따라 색상이 달라 보이는 문제**가 발생한다.

예를 들어, 빨간 공이라 하더라도 밝은 조명 아래에서는 훨씬 밝은 빨강, 어두운 그림자 아래에서는 탁한 붉은 갈색처럼 보일 수 있기 때문이다. 이것은 RGB에서 '색상', '채도', '밝기'가 서로 섞여 표현되기 때문이다.

이 문제를 해결하기 위해 우리는 이미지를 **HSV 색공간으로 변환**한다. HSV는 색상을 **Hue(색상), Saturation(채도), Value(명도)**로 분리하여 표현한다. 이들은 각각 **독립적으로 제어**할 수 있어 색상 기반 필터링에 매우 적합한 색공간이다. 즉, RGB에서 빨간색 하나만 찾으려고 해도 R,G,B 비율을 조정해야 하는데, HSV에서는 H만 보면 되기 때문에 훨씬 쉽게 색상 기반 필터링이 가능하다.

 - Hue는 그야말로 '무슨 색인가'를 결정한다.(빨강, 노랑, 파랑 등)
 - Saturation은 색의 진하기를 나타낸다.
 - Value는 밝기이다.

HSV의 가장 큰 장점은 우리가 **색상만 골라서 객체를 추출할 수 있다는 점**이다. 예를 들어, 빨간 공은 Hue값이 약 0~10 또는 170~180 범위에 나타나므로, 이 범위만 필터링하면 주변 배경이나 조명과 무관하게 빨간 공만 따로 분리할 수 있다. RGB에서는 불가능하거나 복잡한 작업이지만, HSV에서는 이처럼 **색상만 분리해 간단하게 처리**할 수 있다.

**요약**
| 요소         | 역할                                     |
| ---------- | -------------------------------------- |
| Hue        | 실제 색상을 결정 (빨강, 파랑 등)                   |
| Saturation | 색의 진하기 (회색인지 선명한 색인지)                  |
| Value      | 밝기 (밝은 색인지 어두운 색인지)                    |
| inRange 수식 | 이 세 요소가 특정 범위에 있을 때만 ‘해당 색상’이라고 판단     |
| 결과         | 객체가 있는 위치에 흰색, 배경은 검정으로 표현된 마스크 이미지 생성 |

**색상 기반 수식**
$$ 
M(x, y) = \begin{cases} 255 & \text{if } H_{low} \leq H(x, y) \leq H_{high} \\ & \text{and } S_{low} \leq S(x, y) \leq S_{high} \\ & \text{and } V_{low} \leq V(x, y) \leq V_{high} \\ 0 & \text{otherwise} \end{cases} 
$$

**HSV Convert Image**
![Alt text](/Step1_Convert_HSV/images/step1_hsv.jpg)

HSV로 변환한 다음에는 **노이즈 제거**를 한다. 아무리 색상 필터링을 잘 헀더라도, 이미지에는 항상 '잡읍'이 존재한다. 반사광, 그림자, 먼지, 이미지 압축에 따른 아티팩트 등이 노이즈가 된다. 이 잡음이 남아 있으면 우리가 당구공이나 테이블 테두리를 인식할 때 **엉뚱한 것까지 인식하는 오류**가 발생한다.

그래서 우리는 OpenCV의 **형태학적 연산(Morphological Operations)**을 사용한다. 가장 기본적인 연산은 다음과 같다.
 - **Erosion(침식)** : 흰 점 중 주변이 부족한 부분( = 잡음)을 없앰
 - **Dilation(팽창)** : 남은 객체의 모양을 복원

이 둘을 순서대로 적용하면 'Opening 연산'이라고 하며, 이 과정을 통해 **작은 점이나 틈을 제거하면서 테이블 또는 공의 윤곽을 더 정확하게 정리**할 수 있다.

수식으로 표현하면 다음과 같다.
$$
M'(x,y) = D(E(M(x,y)))
$$

여기서 $$M$$은 마스크 이미지이며, $$E$$는 침식, $$D$$는 팽창 연산을 의미한다. 최종적으로 얻은 $$M'$$은 **불필요한 점을 제거하고, 중요한 구조만 남은 정제된 이미지**가 된다.

형태학적 연산 후 영상은 **이진 이미지**라고 한다. HSV 색공간에서 특정 색상 범위(Hue, Saturation, Value)에 해당하는 픽셀을 추출할 때,
우리는 cv::inRange() 함수를 사용해 이진 마스크를 만든다.

```cpp
cv:inRange(hsvImage, lowerBound, upperBound, mask);
```

이렇게 만들어진 mask는 다음과 같은 값을 가진다:
 - 255(흰색) : 조건을 만족하는 픽셀(예: 빨간 공, 파란 테이블 등 우리가 찾는 대상)
 - 0(검은색) : 조건을 만족하지 않는 모든 배경

즉, mask는 색상 기반으로 분리한 **이진 이미지**이다. 여기에 형태학적 연산(erode, dilate)를 적용하면:
 - 불필요하게 남은 하얀 점들(잡음)은 제거되고
 - 유효한 흰색 영역(공이나 테이블 등)은 더 깔끔하게 유지된다.

처리 단계에 따른 결과 형태는 아래와 같다.

| 처리 단계                      | 결과 형태             |
| -------------------------- | ----------------- |
| HSV 변환                     | 컬러 이미지            |
| `inRange()` 마스크            | 흰색(관심영역) + 검정(배경) |
| Morphological Opening 적용 후 | 노이즈가 사라진 흰-검 마스크  |

**Binary image**
![Alt text](/Step2_table_mask/images/step2_table_mask_green.jpg)

정리하자면,
 - **HSV 색공간 변환**은 조명 영향 없이 색상 기반 필터링을 가능하게 하여, 공과 테이블을 쉽게 구분할 수 있게 한다.
 - **형태학적 노이즈 제거**는 작은 잡음들을 없애고, 윤곽선이나 객체 중심 검출의 정확도를 높이는 데 필수적인 과정이다.

이 두 가지 작업은 영상 처리에서 가장 기본이자 중요한 시작점이며, **정확한 후속 작업(윤곽선 추출, 공 인식 등)을 귀한 기반**이 된다.

# 2. 당구대 영역 검출 단계에서 왜 마스크에서 윤곽선을 검출하는가?
+ "마스크"란?, 볼록 다각형으로 보정하는 이유?

**마스크(mask)**란 이미지에서 **특정 영역만 흰색(255)**으로, **나머지 영역은 검은색(0)**으로 처리한 **이진 이미지**를 말한다. 우리가 앞 단계에서 HSV를 기준으로 파란 테이블을 추출할 때 사용했던 **cv::inRange()** 함수 결과가 바로 **마스크**이다.

예를 들어, 당구대의 색상이 파란색이라고 할 때 Hue 값이 대략 110~130 범위에 있다. 이 범위 안에 있는 픽셀은 흰색(255), 그 외의 픽셀은 검정(0)으로 마스크가 생성된다.

이렇게 만들어진 마스크는 **"우리가 관심있는 영역(ROI, Region of Interest)**만 남기고 나머지는 전부 무시하겠다."는 의도이다.

**왜 마스크에서 윤곽선을 검출하는가?** : 우리가 테이블의 **경계(외곽)**를 알고 싶은 이유는 나중에 공의 좌표를 **픽셀 좌표에서 실세계 단위(mm)**로 바꿔야 하기 때문이다. 이때 기준이 되는 것이 바로 당구대의 네 꼭짓점(코너)이다.

그런데 이미지에는 테이블, 공, 그림자, 주변 벽 등 다양한 물체가 존재하고, 우리는 그중 **테이블의 가장 바깥 경계만 추출**하고 싶어한다.

그래서 이 마스크를 **cv::fiindContours()** 함수에 넣으면 **흰색 영역의 외곽선을 선처럼 따라가며 벡터 형태로 추출**할 수 있다. 이때 가장 큰 면적의 윤곽선(contour)을 선택하면 대개 테이블 전체의 테두리 곡선이 된다.

**왜 볼록 다각형(convex hull)으로 보정하는가?** : 윤곽선은 굉장히 울퉁불퉁한 경계일 수 있다. 예를 들어 테이블이 아주 약간 왜곡돼 있거나, 마스크가 조금씩 잘못 나와있으면 원래는 직선인 테두리가 비정상적으로 휘거나 삐뚤빼뚤할 수 있다. 

이 문제를 해결하기 위해 우리는 **cv::approxPolyDP()**로 먼저 꼭짓점을 단순화하고, 
그 다음 **cv::convexHull()**을 사용해 **가장 바깥쪽을 감싸는 볼록 다각형 형태로 정제**한다.

여기서 **Convex Hull(볼록 껍질)**이란, 모든 점들을 감싸면서, 어떤 두 점을 연결한 직선도 다각형 안에 존재하는 가장 단순한 외곽선을 의미한다. 쉽게 말해, 물건을 비닐 랩으로 감쌌을 때의 '랩 경계'같은 것이다.

![Alt text](/images/ConvexHull.png)

이걸 이용하는 이유는 딱 하나 **"정확한 네 꼭짓점 정보를 얻기 위해"**서이다. 이 꼭짓점은 Step4에서 공의 위치를 실제 mm 단위로 변환할 때 스케일 기준점이 되기 때문에 아주 중요하다.

![Alt text](/images/step3_corners_green.jpg)

**관련 수식(윤곽선 면적 기준 선택)**
1. **findContours**로 얻은 윤곽선 집합 $$C_1, C_2,...,C_n$$에 대해,
2. 면적이 가장큰 윤곽선 $$C_{max}$$을 선택 : 
$$
C_{max} = argmaxArea(C_i)
$$
3. 이를 꼭짓점 근사화(Ramer-Douglas-Peucker 알고리즘):
$$
P' = approxPoluDP(C_{max},ϵ)
$$
4. 그 다음 볼록 다각형으로 보정:
$$
H = convexHull(P')
$$

**요약**
| 항목          | 설명                           |
| ----------- | ---------------------------- |
| 마스크         | 특정 색상을 기준으로 만든 흑백 이진 이미지     |
| 윤곽선 검출      | 마스크에서 흰색 영역의 테두리를 추출         |
| convex hull | 울퉁불퉁한 경계를 정리해주는 볼록 다각형       |
| 최종 목적       | 테이블의 네 꼭짓점을 얻어 좌표 변환 기준으로 사용 |

# 왜 영상처리 파이프라인을 지금과 같은 순서로 진행했는가?
**사용한 파이프라인 순서**
 
 1. 이미지 전처리(HSV 변환, 노이즈 제거)
 2. 테이블 색상 분리(Masking)
 3. 테이블 외곽선 및 꼭짓점 추출(Contour + Convex Hull)
 4. 공 검출(색상 기반 + Hough 원 검출)
 5. 좌표 변환(픽셀 -> mm)

이 순서는 **객체 인식을 위한 영상 처리의 전형적인 흐름**을 따르고 있다.

**왜 이 순서를 따르는가?** : 영상 처리에서 **가장 먼저 해야 할 일은 '잡소리 제거', 즉 우리가 원하는 정보만 남기고, 나머지는 제거하는 것**이다. 이것을 **전처리**라고 부른다.

그 다음에는 **관심 있는 영역(ROI)을 식별**해야 하고, 
그 후 **형태나 위치를 계산**하고, 마지막으로 **실제 응용(측정, 분류, 추적 등)**으로 넘어간다.

이걸 일반적인 흐름으로 표현하면 다음과 같다.

```css
[입력 이미지] 
   ↓  
[전처리: 색공간 변환, 노이즈 제거]
   ↓  
[분할(Segmentation): 관심 객체만 추출]
   ↓  
[형태 분석: 윤곽선, 꼭짓점, 원 검출]
   ↓  
[좌표 변환 및 응용 단계]
```

당구공을 인식하는 것은 분류 문제이기보단, **객체 인식(Object Detection)과 형태 분석(Shape Analysis)**에 가깝다. 
 - 분류 문제 : 이미지 전체가 어떤 클래스인지 구분하는 문제
 - 객체 인식 : 이미지 속에서 무엇이 어디에 있는지를 찾는 문제

당구 영상에서는 전체 화면에서
 - 당구대가 어디 있는지
 - 공이 어디 있는지
 - 각각이 어떤 색상인지 파악해야 하므로

이건 위치 정보가 포함된 **탐지(Detection)** 문제이다. 그리고 이 탐지는 주로 다음 2가지 메커니즘을 따른다.

**영상 기반 객체 인식의 일반적인 메커니즘**
 1. **Bottom-up 방식(데이터 기반)** : 이미지에서부터 **픽셀 단위의 특징(Hue, 모양, 질감 등)**을 모으고 그걸 기반으로 큰 의미(테이블, 공 등)를 추론하는 방식

  - 당구공 인식에서 사용한 방식은 색상 기반 마스킹, 윤곽선 찾기, 꼭짓점 검출, 원 중심 탐지 즉, Low Level 정보로 High Level 객체를 탐지한 것이다.

 2. **Top-down 방식(모델 기반)** : "이건 직사각형일 것이다", "공은 원형일 것이다"처럼 사전에 알고 있는 모델(기하학 형태, 특징)을 바탕으로 이미지에서 해당 패턴을 찾는 방식 

  - 당구공 인식에서는 **Hough Circle Transform**을 사용할 때 이 방식을 활용했다. (공은 원이다 -> 원 형태만 찾음)

**요약**
| 단계                | 이유                                                  |
| ----------------- | --------------------------------------------------- |
| HSV 변환            | 색상 기반 분리를 위해 (조명 무시)                                |
| 마스킹               | 테이블만 남기기 위해                                         |
| 윤곽선 + Convex Hull | 꼭짓점 계산 및 좌표 변환 기준 확보                                |
| 공 검출              | 색상 + 모양 기반으로 공의 중심 검출                               |
| 순서 전체             | 하위 정보 → 객체 분석으로 가는 Bottom-up 방식 + 일부 Top-down 결합 구조 |

# 왜 공 인식 전에 밝기 성분(value)을 제거하고, 색상(Hue)과 채도(Saturation)만 비교하는가?

**이미지에서 밝기의 영향** : 실제 촬영된 이미지를 생각해보면, 조명은 항상 완벽하지 않다. 카메라의 각도, 주변 광원, 반사 등으로 인해 공의 밝기가 다르게 보이는 경우가 많다. 

예를 들어 똑같은 빨간 공이라도:
 - 조명을 바로 받으면 밝고 연한 붉은색으로 보이고
 - 그림자 속에서는 어두운 갈색처럼 보인다.

이런 현상이 바로 영상의 밝기(Value) 채널이 바뀌면서 생기는 문제이다.

| 요소             | 의미 | 영향                   |
| -------------- | -- | -------------------- |
| H (Hue)        | 색상 | 실제 어떤 색인가 (빨강, 노랑 등) |
| S (Saturation) | 채도 | 색의 진함 (흐리냐 선명하냐)     |
| V (Value)      | 밝기 | 얼마나 밝은가 (광원 영향 받음)   |

여기서 V는 조명 변화에 가장 민감한 요소이다. 그래서 같은 객체라도 V값이 바뀌면 전혀 다른 색처럼 보일 수 있다.

**해결 방법: Value 제거 => Hue와 Saturation 중심 필터링**
우리가 색상 기반으로 공을 찾을 때, cv::inRange()에서 조건을 아래와 같이 설정해보자.

```cpp
cv::Scalar lowerRed(0, 100, 100);
cv::Scalar upperRed(10, 255, 255);
```

여기서 S(채도)와 V(밝기)에 **최소값을 설정**하고, **Hue 중심으로 판단**한다는 건 결국 다음을 의미한다. : 
 - 채도가 너무 탁하거나 흐리면 제외(S<100)
 - 밝기는 너무 어두운 픽셀 제외(V<100)
 - 그 외에는 색상(H) 중심으로 판단

즉, Hue는 그대로 사용하지만 Value는 걸러내는 기준으로만 활용하고 객체 검출의 기준은 되도록 사용하지 않는 것이다.

> 밝기(Value)는 조명에 따라 변동이 크기 때문에, 색상 기반 탐지를 할 때는 Hue(색상)와 Saturation(채도) 위주로 판단하고, Value는 신뢰하지 말고 필터링에만 활용하는 것이 일반적인 원칙이다.

# 차광 환경?
이미지에서 객체를 인식할 때 가장 자주 발생하는 오류 중 하나가 바로 **빛에 의한 반사나 그림자**때문이다.
 - 당구공은 매끄럽고 광택이 있기 때문에 빛을 반사한다.
 - 테이블 표면도 일부는 밝게, 일부는 어둡게 보일 수 있다.
 - 같은 색 공이라도 조명 방향에 따라 전혀 다른 색상과 밝기 값으로 인식될 수 있다.

즉, "색깔만 보고 객체를 인식"하기 위해 조명의 영향을 줄여야한다.

차광 현상이란 : 빛의 반사나 조명 조건의 변화를 최대한 줄이고, 일관된 광원과 환경 조건을 유지하여 영상 분석의 정확도를 높이는 환경을 의미한다.

즉, 외부 조명 영향을 받지 않도록 막거나 제어하는 공간을 의미한다. 카메라 인식 정확도를 높이기 위해 **광원 조건을 고정하고, 주변 빛을 차단하는 것이 핵심이다.**

해당 실험을 통해 직면한 문제는 아래와 같다.
 - 흰 공 주변에 반사광이 생겨서 테이블 위의 하얀 반사 영역도 공처럼 인식됨
 - 빨간공은 반사광 때문에 색이 희게 변해서 아예 인식이 안됨

**조치 사항**

| 조치 사항                      | 설명                               | 코드에서 관련된 함수 또는 처리 위치                                                                                        |
| -------------------------- | -------------------------------- | ----------------------------------------------------------------------------------------------------------- |
| **형광등, 직접 조명 차단**          | 공 표면이 강한 조명 반사로 인해 흰색 영역이 생기던 문제 | `cv::inRange()`로 만든 HSV 마스크의 결과가 더 안정적으로 나옴 <br>→ 관련 함수: `findBallCenters_*()` 내부에서 `cv::inRange()`         |
| **테이블 주변 흰 벽 or 유광 바닥 가림** | 주변 반사광이 검출되던 것을 방지함              | `maskTableArea()` 함수 내 HSV 마스킹이 불필요한 픽셀까지 포함하지 않게 됨 <br>→ 관련 함수: `cv::inRange()` in `maskTableArea()`       |
| **조명 각도 조절 (간접광, 천장광 위주)** | 당구공에서 하이라이트(빛 반사) 영역이 줄어듦        | `cv::HoughCircles()`의 정확도 향상 <br>→ 관련 함수: `findBallCenters_HSV_Hough()` / `_Red()` 내부의 `cv::HoughCircles()` |
| **카메라 위치 고정**              | 테이블의 위치가 일정해짐 → 윤곽선 검출이 안정화      | `extractTableCorners()` 함수에서 `findContours()` + `convexHull()` 정확도 향상                                       |
| **하이라이트 줄이기 위한 각도 조절**     | 공 주변의 밝은 점들이 ‘공’으로 오인되는 것 방지     | `cv::HoughCircles()`에서 불필요한 작은 원 검출 감소 <br>→ `findBallCenters_HSV_Hough()` 내부                               |
